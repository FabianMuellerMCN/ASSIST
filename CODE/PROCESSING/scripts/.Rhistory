colnames(df)
# identify columns to remove
cols_to_remove <- grep("Trials.jitDelay.", names(df))
# remove columns
df <- df[ , -cols_to_remove]
View(df)
# identify columns to remove
cols_to_remove <- grep("Trials.jitDelay."|"Trials.fadingin_duration", names(df))
# identify columns to remove
cols_to_remove <- grep("Trials.jitDelay.|Trials.fadingin_duration", names(df))
# remove columns
df <- df[ , -cols_to_remove]
View(df)
View(df)
jsonFile = "/Users/interface/Desktop/DATA_ANALYSIS/input/json/PID_4_2023-04-06T11:46:09_Trials.json")
jsonFile = "/Users/interface/Desktop/DATA_ANALYSIS/input/json/PID_4_2023-04-06T11:46:09_Trials.json"
json <- fromJSON(file = jsonFile)
df <- as.data.frame(json)
View(df)
# Short Preprocessing Script
# Script PreProcessing QUEST Data from Threshold Experiment #-------------------------------------------------------------------------------------------------------
#---- set system language to "en", clean workspace, scientific notation ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
rm(list = ls())
options("scipen"=100, "digits"=5)
options(stringsAsFactors = F)
#---- load all the required packages -------------------------------------------------------------------------------------------------------------------------
library(dplyr)
library(rjson)
library(tidyr)
library(reshape2)
#---- set processing path  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
PROCESSING_PATH = "/Volumes/dcn_CONVERGENCE/DATA_ANALYSIS/"
PROCESSING_PATH = "/Users/interface/Desktop/CONVERGENCE/DATA_ANALYSIS/"                        #Fabian when offline
#---- set directories path  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
idir = paste0(PROCESSING_PATH, "input/") # data-(input)directory
idir_sosci = paste0(PROCESSING_PATH, "input/","sosci/") # data-(input)directory
idir_json = paste0(PROCESSING_PATH, "input/","json/") # json-directory
sdir = paste0(PROCESSING_PATH, "scripts/") # scripts directory
fdir = paste0(PROCESSING_PATH, "scripts/","functions/") # scripts directory
odir =  paste0(PROCESSING_PATH, "output/", gsub("-", "_", Sys.Date()))# output-directory
dir.create(odir)
jsonFile = "/Users/interface/Desktop/DATA_ANALYSIS/input/json/PID_4_2023-04-06T11:46:09_Trials.json"
#jsonFile = paste0((idir_json),"/data.json")
json <- fromJSON(file = jsonFile)
View(json)
df <- as.data.frame(json)
View(df)
View(df)
colnames(df)
# identify all columns to remove
cols_to_remove <- grep("Trials.trialduration|Trials.fadingin_duration|Trials.fadingout_duration", names(df))
# remove columns
df <- df[ , -cols_to_remove]
View(df)
View(df)
# identify the index of the column with the highest value in Trials.estThreshold.XX
max_col_index <- which.max(grep("Trials.trialduration.")
#---- create and select relevant outputs -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
df$TE <- df$Trials.ansThreshold.11 # Replace with latest n Trial
#---- 2.0 transform to long-format for plotting psychometric functions -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# used http://www.cookbook-r.com/Manipulating_data/Converting_data_between_wide_and_long_format/
#---- 2.1 select the columns for the intensities (make subset "y" coding the intensities and melting across PID and trial number)
est = df  %>%
select(PID, Trials.estThreshold , Trials.estThreshold.1, Trials.estThreshold.2, Trials.estThreshold.3, Trials.estThreshold.4, Trials.estThreshold.5, Trials.estThreshold.6, Trials.estThreshold.7, Trials.estThreshold.8, Trials.estThreshold.9, Trials.estThreshold.10, Trials.estThreshold.11)
y = melt(est, id.vars=c("PID"),  variable.name="trial",
value.name="intensity")
y$trial <- gsub("Trials.estThreshold.", "", y$trial)
y$trial <- gsub("Trials.estThreshold", "0", y$trial)
#---- 2.2 select the columns for the responses (make subset "y" coding the intensities and melting across PID and trial number)
resp <- df  %>%
select(PID, TrialType, Trials.ansTrial, Trials.ansTrial.1, Trials.ansTrial.2, Trials.ansTrial.3, Trials.ansTrial.4, Trials.ansTrial.5, Trials.ansTrial.6, Trials.ansTrial.7, Trials.ansTrial.8, Trials.ansTrial.9, Trials.ansTrial.10, Trials.ansTrial.11)
# Here I also included TrialType (e.g., the different distortions)
x = melt(resp, id.vars=c("PID", "TrialType"),  variable.name="trial",
value.name="resp")
x$trial <- gsub("Trials.ansTrial.", "", x$trial)
x$trial <- gsub("Trials.ansTrial", "0", x$trial)
#---- 2.3 select the columns for the actual response ntensities in each trial (make subset "z")
ans = df  %>%
select(PID, Trials.ansThreshold, Trials.ansThreshold.1, Trials.ansThreshold.2, Trials.ansThreshold.3, Trials.ansThreshold.4, Trials.ansThreshold.5, Trials.ansThreshold.6, Trials.ansThreshold.7, Trials.ansThreshold.8, Trials.ansThreshold.9, Trials.ansThreshold.10, Trials.ansThreshold.11)
z = melt(ans, id.vars=c("PID"),  variable.name="trial",
value.name="answer")
z$trial <- gsub("Trials.ansThreshold.", "", z$trial)
z$trial <- gsub("Trials.ansThreshold", "0", z$trial)
# merge dataframes together
ok <- merge(x, y, by = c("PID", "trial"))
ok <- merge(ok, z, by = c("PID", "trial"))
ok$trial <- as.numeric(ok$trial)
ok$trial <- ok$trial + 1
# rename
dat_fit <- ok
return(dat_fit)
}
# identify the index of the column with the highest value in Trials.estThreshold.XX
max_col_index <- which.max(grep("Trials.trialduration."))
# identify columns to extract
cols_to_extract <- grep("Trials.ansThreshold", names(df))
# extract trial IDs from column names
trial_ids <- as.numeric(sub("Trials.ansThreshold.", "", names(df[ , cols_to_extract])))
print(trial_ids)
print(cols_to_extract)
# identify columns to extract
cols_to_extract <- grep("Trials.estThreshold", names(df))
print(cols_to_extract)
# extract trial IDs from column names
trial_ids <- as.numeric(sub("Trials.estThreshold.", "", names(df[ , cols_to_extract])))
print(trial_ids)
# extract trial IDs from column names
trial_ids <- as.numeric(sub("Trials.estThreshold", "", names(df[ , cols_to_extract])))
print(trial_ids)
# identify columns to extract
cols_to_extract <- grep("Trials.estThreshold", names(df))
print(cols_to_extract)
# extract trial IDs from column names
trial_ids <- as.numeric(gsub("Trials.ansThreshold.", "", names(df[ , cols_to_extract])))
trial_ids
# identify columns to extract
cols_to_extract <- grep("^Trials\\.ansThreshold\\.\\d+$", names(df))
cols_to_extract
# identify columns to extract
cols_to_extract <- grep("Trials.estThreshold.", names(df))
# extract trial IDs from column names
trial_ids <- as.numeric(gsub("Trials.ansThreshold.", "", names(df[ , cols_to_extract])))
library(stringr)
# identify columns to extract
cols_to_extract <- grep("Trials.estThreshold", names(df))
# extract trial IDs from column names
trial_ids <- as.numeric(str_extract(names(df[ , cols_to_extract]), "(?<=Trials\\.estThreshold\\.)\\d+"))
trial_ids
# identify columns to extract
cols_to_extract <- grep("Trials.estThreshold", names(df))
# extract trial IDs from column names
trial_ids <- as.numeric(gsub("Trials.estThreshold.", "", names(df[ , cols_to_extract])))
# extract trial IDs from column names
trial_ids <- as.numeric(gsub("Trials.estThreshold.", "", names(df[ , cols_to_extract])))
# identify columns to extract
cols_to_extract <- grep("Trials.estThreshold.", names(df))
cols_to_extract
# extract trial IDs from column names
trial_ids <- as.numeric(sub("Trials.estThreshold.", "", names(df[ , cols_to_extract])))
trial_ids
# identify the index of the highest trial ID
max_trial_index <- which.max(trial_ids)
max_trial_index
# identify the index of the highest trial ID
max_trial_index <- which.max(cols_to_extract)
max_trial_index
cols_to_extract
# extract trial IDs from column names
trial_ids <- as.numeric(str_extract(names(df[ , cols_to_extract]), "(?<=Trials\\.estThreshold\\.)\\d+"))
trial_ids
# extract trial IDs from column names
trial_ids <- as.numeric(sub("Trials.estThreshold", "", names(df[ , cols_to_extract])))
trial_ids
# extract trial IDs from column names
library(stringr)
trial_ids <- as.numeric(str_extract(names(df[ , cols_to_extract]), "(?<=Trials\\.estThreshold\\.)\\d+"))
trial_ids
str_extract("Trials.estThreshold.22", "(?<=Trials\\.estThreshold\\.)\\d+")
# identify columns to extract
cols_to_extract <- grep("Trials.estThreshold.", names(df))
# extract trial IDs from column names
library(stringr)
trial_ids <- as.numeric(str_extract(names(df[ , cols_to_extract]), "(?<=Trials\\.estThreshold\\.)\\d+"))
trial_ids
str_extract("Trials.estThreshold.22", "(?<=Trials\\.estThreshold\\.)\\d+")
trial_ids <- str_extract(names(df[ , cols_to_extract]), "(?<=Trials\\.estThreshold\\.)\\d+")
trial_ids
cols_to_extract
trial_ids <- str_extract(df[ , cols_to_extract], "(?<=Trials\\.estThreshold\\.)\\d+")
trial_ids
trial_ids <- str_extract(names(df[ , cols_to_extract]), "(?<=Trials\\.estThreshold\\.)\\d+"))
trial_ids <- str_extract(names((df[ , cols_to_extract]), "(?<=Trials\\.estThreshold\\.)\\d+"))
trial_ids <- as.numeric(str_extract(names(df[ , cols_to_extract]), "(?<=Trials\\.estThreshold\\.)\\d+"))
trial_ids
names(df)
names(df[,cols_to_extract])
trial_ids <- as.numeric(str_extract(names(df[ , cols_to_extract]), "(?<=Trials.estThreshold.)\\d+"))
trial_ids
# identify the index of the highest trial ID
max_trial_index <- which.max(trial_ids)
max_trial_index
ID <- str_extract("Trials.estThreshold.22", "(?<=Trials\\.estThreshold\\.)\\d+")
# identify columns to extract
cols_to_extract <- grep("Trials.estThreshold.", names(df))
# extract trial IDs from column names
library(stringr)
trial_ids <- as.numeric(str_extract(names(df[ , cols_to_extract]), "(?<=Trials\\.estThreshold\\.)\\d+"))
as.numeric(str_extract(names(df[ , cols_to_extract]), "(?<=Trials\\.estThreshold\\.)\\d+"))
cols_to_extract
trial_ids <- (str_extract(names(df[ , cols_to_extract]), "(?<=Trials\\.estThreshold\\.)\\d+"))
trial_ids <- (str_extract(names(df[ , cols_to_extract]), "(?<=Trials\\.estThreshold\\.)\\d+"))
names(cols_to_extract)
names(df[ , cols_to_extract]
)
?stringr
# Short Preprocessing Script
# Script PreProcessing QUEST Data from Threshold Experiment #-------------------------------------------------------------------------------------------------------
#---- set system language to "en", clean workspace, scientific notation ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
rm(list = ls())
options("scipen"=100, "digits"=5)
options(stringsAsFactors = F)
#---- load all the required packages -------------------------------------------------------------------------------------------------------------------------
library(dplyr)
library(rjson)
library(tidyr)
library(reshape2)
library(stringr)
#---- set system language to "en", clean workspace, scientific notation ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
rm(list = ls())
options("scipen"=100, "digits"=5)
options(stringsAsFactors = F)
#---- load all the required packages -------------------------------------------------------------------------------------------------------------------------
library(dplyr)
library(rjson)
library(tidyr)
library(reshape2)
library(stringr)
# Short Preprocessing Script
# Script PreProcessing QUEST Data from Threshold Experiment #-------------------------------------------------------------------------------------------------------
#---- set system language to "en", clean workspace, scientific notation ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
rm(list = ls())
options("scipen"=100, "digits"=5)
options(stringsAsFactors = F)
#---- load all the required packages -------------------------------------------------------------------------------------------------------------------------
library(dplyr)
library(rjson)
library(tidyr)
library(reshape2)
library(stringr)
#---- set processing path  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
PROCESSING_PATH = "/Volumes/dcn_CONVERGENCE/DATA_ANALYSIS/"
PROCESSING_PATH = "/Users/interface/Desktop/CONVERGENCE/DATA_ANALYSIS/"                        #Fabian when offline
#---- set directories path  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
idir = paste0(PROCESSING_PATH, "input/") # data-(input)directory
idir_sosci = paste0(PROCESSING_PATH, "input/","sosci/") # data-(input)directory
idir_json = paste0(PROCESSING_PATH, "input/","json/") # json-directory
sdir = paste0(PROCESSING_PATH, "scripts/") # scripts directory
fdir = paste0(PROCESSING_PATH, "scripts/","functions/") # scripts directory
odir =  paste0(PROCESSING_PATH, "output/", gsub("-", "_", Sys.Date()))# output-directory
dir.create(odir)
jsonFile = "/Users/interface/Desktop/DATA_ANALYSIS/input/json/PID_4_2023-04-06T11:46:09_Trials.json"
#jsonFile = paste0((idir_json),"/data.json")
json <- fromJSON(file = jsonFile)
#result <- fromJSON(file = "/Users/fmueller/Desktop/data.json")
df <- as.data.frame(json)
# 1. remove unnecessary colums:
# identify all columns to remove
cols_to_remove <- grep("Trials.trialduration|Trials.fadingin_duration|Trials.fadingout_duration", names(df))
# remove columns
df <- df[ , -cols_to_remove]
# identify columns to extract
cols_to_extract <- grep("Trials.estThreshold.", names(df))
# extract trial IDs from column names
trial_ids <- as.numeric(str_extract(names(df[ , cols_to_extract]), "(?<=Trials\\.estThreshold\\.)\\d+"))
View(df)
View(df)
df <- as.data.frame(json)
View(df)
# identify all columns to remove
cols_to_remove <- grep("Trials.trialduration|Trials.fadingin_duration|Trials.fadingout_duration", names(df))
# remove columns
df <- df[ , -cols_to_remove]
# identify columns to extract
cols_to_extract <- grep("Trials.estThreshold.", names(df))
trial_ids
# extract trial IDs from column names
trial_ids <- as.numeric(str_extract(names(df[ , cols_to_extract]), "(?<=Trials\\.estThreshold\\.)\\d+"))
trial_ids
cols_to_extract
View(df)
ID <- str_extract("Trials.estThreshold.22", "(?<=Trials\\.estThreshold\\.)\\d+")
est = df  %>%
select(PID, Trials.estThreshold , Trials.estThreshold.1, Trials.estThreshold.2, Trials.estThreshold.3, Trials.estThreshold.4, Trials.estThreshold.5, Trials.estThreshold.6, Trials.estThreshold.7, Trials.estThreshold.8, Trials.estThreshold.9, Trials.estThreshold.10, Trials.estThreshold.11)
y = melt(est, id.vars=c("PID"),  variable.name="trial",
value.name="intensity")
View(y)
y$trial <- gsub("Trials.estThreshold.", "", y$trial)
y$trial <- gsub("Trials.estThreshold", "0", y$trial)
View(y)
#---- 2.2 select the columns for the responses (make subset "y" coding the intensities and melting across PID and trial number)
resp <- df  %>%
select(PID, TrialType, Trials.ansTrial, Trials.ansTrial.1, Trials.ansTrial.2, Trials.ansTrial.3, Trials.ansTrial.4, Trials.ansTrial.5, Trials.ansTrial.6, Trials.ansTrial.7, Trials.ansTrial.8, Trials.ansTrial.9, Trials.ansTrial.10, Trials.ansTrial.11)
# Here I also included TrialType (e.g., the different distortions)
x = melt(resp, id.vars=c("PID", "TrialType"),  variable.name="trial",
value.name="resp")
x$trial <- gsub("Trials.ansTrial.", "", x$trial)
x$trial <- gsub("Trials.ansTrial", "0", x$trial)
View(x)
View(df)
View(df)
View(df)
resp <- df  %>%
select(PID, TrialType, Trials.ansTrial, Trials.ansTrial.1, Trials.ansTrial.2, Trials.ansTrial.3, Trials.ansTrial.4, Trials.ansTrial.5, Trials.ansTrial.6, Trials.ansTrial.7, Trials.ansTrial.8, Trials.ansTrial.9, Trials.ansTrial.10, Trials.ansTrial.11)
View(resp)
# Here I also included TrialType (e.g., the different distortions)
x = melt(resp, id.vars=c("PID", "TrialType"),  variable.name="trial",
value.name="resp")
x$trial <- gsub("Trials.ansTrial.", "", x$trial)
x$trial <- gsub("Trials.ansTrial", "0", x$trial)
View(x)
ans = df  %>%
select(PID, Trials.ansThreshold, Trials.ansThreshold.1, Trials.ansThreshold.2, Trials.ansThreshold.3, Trials.ansThreshold.4, Trials.ansThreshold.5, Trials.ansThreshold.6, Trials.ansThreshold.7, Trials.ansThreshold.8, Trials.ansThreshold.9, Trials.ansThreshold.10, Trials.ansThreshold.11)
z = melt(ans, id.vars=c("PID"),  variable.name="trial",
value.name="answer")
z$trial <- gsub("Trials.ansThreshold.", "", z$trial)
# merge dataframes together
ok <- merge(x, y, by = c("PID", "trial"))
ok <- merge(ok, z, by = c("PID", "trial"))
View(ok)
ok$trial <- as.numeric(ok$trial)
ok$trial <- ok$trial + 1
# rename
dat_fit <- ok
source("~/.active-rstudio-document")
load("/Users/interface/Documents/GitHub/ASSIST/DATA/dat_Analyse_PROTOCOLL.RData")  # MAKE SURE TO ADJUST PATH!
## ADDITIONAL ANALYSIS FOR REVISION ****
library(dplyr)
library(effectsize)
library(ggpubr)
library(nlme)
library(gtools)
library(lme4)
library(scatr)
library(jmv)
library(ggplot2)
library(reshape)
library(gridExtra)
library(tidyr)
library(stats)
library(emmeans)
library(Rmisc)
library(r2glmm)
library(psych)
library(car)
library(palmerpenguins)
# 3.2 In addition to demographics, a number of measures have been collected after VR treatment in the lab
# that may distinguish between participants who succeeded in using the app at home and those who did not
# symptoms of cybersickness, presence in VR, VR app acceptability and usability, subjective improvement after app use on 3 measures).
# Were any of those measures predictive of continued participation vs drop-out?
#---- set system language to "en", clean workspace, scientific notation ----------------------------------------------------
rm(list = ls())
options("scipen"=100, "digits"=5)
options(stringsAsFactors = F)
#options(contrasts=c(unordered="contr.sum", ordered="contr.poly"))
load("/Users/fmueller/Documents/GitHub/ASSIST/DATA/dat_Analyse_PROTOCOLL.RData")  # MAKE SURE TO ADJUST PATH!
load("/Users/interface/Documents/GitHub/ASSIST/DATA/dat_Analyse_PROTOCOLL.RData")  # MAKE SURE TO ADJUST PATH!
# CHECKS ###------------------------------------------------------------------------
# CHECKS ###------------------------------------------------------------------------
noncompleters <-  subset(datAnalyse, Dropout_visit_2 == 1) # dropouts in phase 2!
length(unique(noncompleters$VP_Nr))
TG_noncompleters <- subset(noncompleters, Condition == 1)
#CG_noncompleters <- subset(noncompleters, Condition == 0)
TG_completers <- subset(noncompleters, Condition == 1)
#CHECKS: Good 13 dropouts in study phase 2 in TG and 1 dropout in CG
length(unique(TG_noncompleters$VP_Nr))
length(unique(CG_noncompleters$VP_Nr))
filt_data <- datAnalyse[datAnalyse$Intervention_Phase != "post2", ]
# CHECK
test <- completers[,c("VP_Nr", "Intervention_Phase","Blickv_Verbesserung")]
filt_Treatmentgroup <- subset(filt_data, Condition == 1)
completers <- filter(filt_Treatmentgroup, Dropout_visit_2 == 0)
noncompleters <- filter(filt_Treatmentgroup, Dropout_visit_2 == 1)
# CHECK
test <- completers[,c("VP_Nr", "Intervention_Phase","Blickv_Verbesserung")]
View(test)
summarySE(filt_Treatmentgroup, measurevar="IPQ_Score", groupvars=c("Dropout_visit_2"), na.rm = TRUE)
shapiro.test(completers$IPQ_Score)
shapiro.test(noncompleters$IPQ_Score)
shapiro.test(completers$IPQ_Score)
names(datAnalyse)
# Select Data for Treatment condition only
Treatmentgroup <- subset(datAnalyse, Condition == 1)
# Reduce Dataframe to relevant variables
red_dat <-
Treatmentgroup %>%
select(c("VP_Nr","App_ASSIST_training_min-mean",))
View(red_dat)
# Reduce Dataframe to relevant variables
red_dat <-
Treatmentgroup %>%
select(c("VP_Nr","Intervention_Phase","Angst_im_moment","Angst_Augenkontakt", "relativeDwelltimeAOI",
"App_ASSIST-nTrainings","App_ASSIST_fearMaximumLevel-mean", "App_ASSIST_training_min-mean",
"App_ASSIST_level-mean", "App_ASSIST_fear-mean", "Age", "Sex"))
View(red_dat)
# Reduce Dataframe to relevant variables
red_dat <-
Treatmentgroup %>%
select(c("VP_Nr","Intervention_Phase","Angst_im_moment","Angst_Augenkontakt", "relativeDwelltimeAOI", "Age", "Sex","App_ASSIST-nTrainings",
"App_ASSIST_fearMaximumLevel-mean", "App_ASSIST_training_min-mean", "App_ASSIST_level-mean", "App_ASSIST_fear-mean", "Age", "Sex"))
select(c("VP_Nr","Intervention_Phase","Angst_im_moment","Angst_Augenkontakt", "relativeDwelltimeAOI", "Age", "Sex","App_ASSIST-nTrainings",
View(red_dat)
# Reduce Dataframe to relevant variables
red_dat <-
Treatmentgroup %>%
select(c("VP_Nr","Intervention_Phase","Angst_im_moment","Angst_Augenkontakt", "relativeDwelltimeAOI", "Age", "Sex","App_ASSIST-nTrainings"))
# Reduce Dataframe to relevant variables
red_dat <-
Treatmentgroup %>%
select(c("VP_Nr","Intervention_Phase","Angst_im_moment","Angst_Augenkontakt", "relativeDwelltimeAOI", "Age", "Sex","App_ASSIST-nTrainings"))
# Reduce Dataframe to relevant variables
red_dat <-
Treatmentgroup %>%
select(c("VP_Nr","Intervention_Phase","Angst_im_moment","Angst_Augenkontakt", "relativeDwelltimeAOI", "Age", "Sex","App_ASSIST-nTrainings"))
View(red_dat)
# Convert the dataset from long format to wide format
red_dat_wide <- red_dat %>%
spread(key = Intervention_Phase, value = Angst_im_moment)
View(red_dat_wide)
# Convert the dataset from long format to wide format
red_dat_wide <- red_dat %>%
pivot_wider(names_from = Intervention_Phase, values_from = Angst_im_moment)
View(red_dat_wide)
# Reduce Dataframe to relevant variables
red_dat <-
Treatmentgroup %>%
select(c("VP_Nr","Intervention_Phase","Angst_im_moment","Angst_Augenkontakt", "relativeDwelltimeAOI", "Age", "Sex"))#,"App_ASSIST-nTrainings"))
# Reduce Dataframe to relevant variables
red_dat <-
Treatmentgroup %>%
select(c("VP_Nr","Intervention_Phase","Angst_im_moment","Angst_Augenkontakt", "relativeDwelltimeAOI", "Age", "Sex"))#,"App_ASSIST-nTrainings"))
# Convert the dataset from long format to wide format
red_dat_wide <- red_dat %>%
pivot_wider(names_from = Intervention_Phase, values_from = Angst_im_moment)
View(red_dat_wide)
View(red_dat_wide)
# Reduce Dataframe to relevant variables
red_dat <-
Treatmentgroup %>%
select(c("VP_Nr","Intervention_Phase","Angst_im_moment",, "Age", "Sex")) #"Angst_Augenkontakt", "relativeDwelltimeAOI"#,"App_ASSIST-nTrainings"))
# Reduce Dataframe to relevant variables
red_dat <-
Treatmentgroup %>%
select(c("VP_Nr","Intervention_Phase","Angst_im_moment", "Age", "Sex")) #"Angst_Augenkontakt", "relativeDwelltimeAOI"#,"App_ASSIST-nTrainings"))
# Convert the dataset from long format to wide format
red_dat_wide <- red_dat %>%
pivot_wider(names_from = Intervention_Phase, values_from = Angst_im_moment)
View(red_dat_wide)
# Remove rows with NAs using complete.cases()
CC <- data[complete.cases(red_dat_wide), ]
# Remove rows with NAs using complete.cases()
CC <- red_dat_wide[complete.cases(red_dat_wide), ]
View(CC)
# Calculate the delta between timepoint 2 and timepoint 3
red_dat_wide$delta_fear <- red_dat_wide$post2 - red_dat_wide$post1
View(red_dat_wide)
# Calculate the delta between timepoint 2 and timepoint 3
CC$delta_fear <- CC$post2 - CC$post1
# Calculate the delta between timepoint 2 and timepoint 3
CC_delta$delta_fear <- CC$post2 - CC$post1
View(CC)
dat_n <-
Treatmentgroup %>%
select(c("VP_Nr","Intervention_Phase","App_ASSIST-nTrainings")) #"Angst_Augenkontakt", "relativeDwelltimeAOI"#,"App_ASSIST-nTrainings"))
View(dat_n)
# Filter dataset to include only rows with Intervention_Phase == "post2"
dat_n_post2 <- subset(dat_n, Intervention_Phase == "post2")
View(dat_n_post2)
# Filter dataset to include only rows with Intervention_Phase == "post2"
dat_n_post2 <- filter(dat_n, Intervention_Phase == "post2")
View(dat_n_post2)
df <- merge(CC, dat_n_post2, by = "VP_Nr")
View(df)
names(CC)
dat_fin <- df[, c("VP_Nr", "delta_fear", "App_ASSIST_nTrainings", "Age", "Sex")]
names(df)
View(df)
# merge the dataframes CC with the dat_n_post2
df <- merge(CC, dat_n_post2, by = "VP_Nr")
dat_fin <- df[, c("VP_Nr", "delta_fear", "App_ASSIST_nTrainings", "Age", "Sex")]
names(df)
dat_fin <- df[, c("VP_Nr", "delta_fear", "App_ASSIST-nTrainings", "Age", "Sex")]
View(dat_fin)
# rename App_ASSIST-nTrainings to n_train
colnames(dat_fin)[colnames(dat_fin) == "App_ASSIST-nTrainings"] <- "n_train"
View(dat_fin)
D_train <- lm(delta_fear ~ n_train + age + sex, data = dat_fin)
D_train <- lm(delta_fear ~ n_train + Age + Sex, data = dat_fin)
summary(D_train) # n_train: -
D_train %>%
ggplot(aes(x=n_train,y=delta_fear)) +
geom_point(alpha=0.5) +
labs(x= "Number of Trainings", y="Fear Delta")+
geom_smooth(method=lm)
Treatmentgroup$`App_ASSIST_level-mean`
Treatmentgroup$`App_ASSIST_training_min-mean`
dat_n <-
Treatmentgroup %>%
select(c("VP_Nr","Intervention_Phase","App_ASSIST_training_min-mean")) #"Angst_Augenkontakt", "relativeDwelltimeAOI"#,"App_ASSIST-nTrainings"))
# Filter dataset to include only rows with Intervention_Phase == "post2"
dat_n_post2 <- filter(dat_n, Intervention_Phase == "post2")
# merge the dataframes CC with the dat_n_post2
df <- merge(CC, dat_n_post2, by = "VP_Nr")
dat_fin <- df[, c("VP_Nr", "delta_fear", "App_ASSIST_training_min-mean", "Age", "Sex")]
# rename App_ASSIST-nTrainings to n_train
colnames(dat_fin)[colnames(dat_fin) == "App_ASSIST_training_min-mean"] <- "n_train"
D_train <- lm(delta_fear ~ n_train + Age + Sex, data = dat_fin)
summary(D_train) # n_train: -
D_train %>%
ggplot(aes(x=n_train,y=delta_fear)) +
geom_point(alpha=0.5) +
labs(x= "Number of Trainings", y="Fear Delta")+
geom_smooth(method=lm)
D_train %>%
ggplot(aes(x=n_train,y=delta_fear)) +
geom_point(alpha=0.5) +
labs(x= "Number of Trainings", y="App_ASSIST_training_min-mean")+
geom_smooth(method=lm)
D_train %>%
ggplot(aes(x=n_train,y=delta_fear)) +
geom_point(alpha=0.5) +
labs(x= "App_ASSIST_training_min-mean", y="Fear Delta")+
geom_smooth(method=lm)
